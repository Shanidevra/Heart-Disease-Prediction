{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686d6064-e646-4e54-a4ef-6620ab49c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.cm import rainbow\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f13ae-71ba-4460-a6e3-2444218de133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a19b482-8fea-4ae7-8b86-2ea532f53ead",
   "metadata": {},
   "source": [
    "Next, I'll import all the Machine Learning algorithms I will be using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f040fbd-cf41-4e4f-8539-fb2e4eaf23b3",
   "metadata": {},
   "source": [
    "K Neighbors Classifier\r\n",
    "Support Vector Classifier\r\n",
    "Decision Tree Classifier\r\n",
    "Random Forest Classifierier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0e97e-3d20-448c-90ac-f2baa23c067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2663124d-f9a2-4c41-9f22-d66753372af0",
   "metadata": {},
   "source": [
    "Import dataset\n",
    "Now that we have all the libraries we will need, I can import the dataset and take a look at it. The dataset is stored in the file dataset.csv. I'll use the pandas read_csv method to read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c009a70-e929-4625-a2bf-5d15ae3d5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/sunny/OneDrive/Desktop/dataset/heart.data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab3743-6e50-4264-b549-ad7d9f7fa055",
   "metadata": {},
   "source": [
    "The dataset is now loaded into the variable dataset. I'll just take a glimpse of the data using the desribe() and info() methods before I actually start processing and visualizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7be32d3-6f16-46dc-86c8-f811f5d30b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f21d2f2-dbad-4fd0-b4d2-ea27e21d6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac3291-316d-43d1-a4e6-3d5b6cb8c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87393acb-fd3a-474a-af3d-69ca977beb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20, 14\n",
    "plt.matshow(df.corr())\n",
    "plt.yticks(np.arange(df.shape[1]), df.columns)\n",
    "plt.xticks(np.arange(df.shape[1]), df.columns)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d0cf43-d694-4183-ae8c-f8e066947124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb4a17-f455-41ac-bc0c-43dee327c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 8,6\n",
    "plt.bar(df['target'].unique(), df['target'].value_counts(), color = ['red', 'green'])\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel('Target Classes')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of each Target Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e96705-0923-4cc7-98ca-515fe70d1403",
   "metadata": {},
   "source": [
    "Data Processing\n",
    "After exploring the dataset, I observed that I need to convert some categorical variables into dummy variables and scale all the values before training the Machine Learning models. First, I'll use the get_dummies method to create dummy columns for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b106b7-0248-4484-82d0-40d74a4d6d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b58f8-999d-4432-8655-a06a22c3dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardScaler = StandardScaler()\n",
    "columns_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "df[columns_to_scale] = standardScaler.fit_transform(df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29dfba-be47-4da5-934d-6ff682031602",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "X = df.drop(['target'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596c5f9-8587-48fe-b3c2-51d0f789b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_scores = []\n",
    "for k in range(1,21):\n",
    "    clf = KNeighborsClassifier(n_neighbors = k)\n",
    "    clf.fit(X_train, y_train)\n",
    "    knn_scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a273728-75d2-4265-a85c-30836e92e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([k for k in range(1, 21)], knn_scores, color = 'red')\n",
    "for i in range(1,21):\n",
    "    plt.text(i, knn_scores[i-1], (i, knn_scores[i-1]))\n",
    "plt.xticks([i for i in range(1, 21)])\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('K Neighbors Classifier scores for different K values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f6930a-8cad-4a59-bdda-c895491c2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The score for K Neighbors Classifier is {}% with {} nieghbors.\".format(knn_scores[7]*100, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67718e8-7e1a-4c2a-98d7-9811de56e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_scores = []\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in range(len(kernels)):\n",
    "    clf = SVC(kernel = kernels[i])\n",
    "    clf.fit(X_train, y_train)\n",
    "    svc_scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a87f91-8833-486d-bf82-ff347be2d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = rainbow(np.linspace(0, 1, len(kernels)))\n",
    "plt.bar(kernels, svc_scores, color = colors)\n",
    "for i in range(len(kernels)):\n",
    "    plt.text(i, svc_scores[i], svc_scores[i])\n",
    "plt.xlabel('Kernels')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Support Vector Classifier scores for different kernels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb1ea5-27ac-44bd-9e8a-ba031014fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The score for Support Vector Classifier is {}% with {} kernel.\".format(svc_scores[0]*100, 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383b2e0-7e2b-4537-be7a-87967d9e5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_scores = []\n",
    "for i in range(1, len(X.columns) + 1):\n",
    "    clf = DecisionTreeClassifier(max_features = i, random_state = 0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    dt_scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81645970-2a13-4ae5-8f9d-7a5a4bd7c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1, len(X.columns) + 1)], dt_scores, color = 'green')\n",
    "for i in range(1, len(X.columns) + 1):\n",
    "    plt.text(i, dt_scores[i-1], (i, dt_scores[i-1]))\n",
    "plt.xticks([i for i in range(1, len(X.columns) + 1)])\n",
    "plt.xlabel('Max features')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Decision Tree Classifier scores for different number of maximum features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f1ad0-d809-487c-a485-c81f64e3fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The score for Decision Tree Classifier is {}% with {} maximum features.\".format(dt_scores[17]*100, [2,4,18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e20506-d48e-48de-ab54-f40c1d2dd2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores = []\n",
    "estimators = [10, 100, 200, 500, 1000]\n",
    "for i in estimators:\n",
    "    clf = RandomForestClassifier(n_estimators = i, random_state = 0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    rf_scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d4a30b-9258-4535-8820-d4f739e4dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = rainbow(np.linspace(0, 1, len(estimators)))\n",
    "plt.bar([i for i in range(len(estimators))], rf_scores, color = colors, width = 0.8)\n",
    "for i in range(len(estimators)):\n",
    "    plt.text(i, rf_scores[i], rf_scores[i])\n",
    "plt.xticks(ticks = [i for i in range(len(estimators))], labels = [str(estimator) for estimator in estimators])\n",
    "plt.xlabel('Number of estimators')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Random Forest Classifier scores for different number of estimators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c5b42-18b0-4c36-8ff3-cfa391035e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The score for Random Forest Classifier is {}% with {} estimators.\".format(rf_scores[1]*100, [100, 500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0606a-3e1d-4eb9-a075-5ce78b8126f5",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "In this project, I used Machine Learning to predict whether a person is suffering from a heart disease. After importing the data, I analysed it using plots. Then, I did generated dummy variables for categorical features and scaled other features. I then applied four Machine Learning algorithms, K Neighbors Classifier, Support Vector Classifier, Decision Tree Classifier and Random Forest Classifier. I varied parameters across each model to improve their scores. In the end, K Neighbors Classifier achieved the highest score of 87% with 8 nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d74b34-63fe-4337-a977-cf99480700ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ed6f8-9c63-4df3-9d70-03e67c606d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array([[41,0,1,130,204,0,0,172,0,1.4,2,0,2,1]]) \n",
    "\n",
    "# Generate additional random features to make a total of 30 features\n",
    "additional_features = np.random.randn(input_data.shape[0], 17)\n",
    "input_data_with_additional_features = np.concatenate([input_data, additional_features], axis=1)\n",
    "\n",
    "# Make prediction using the classifier\n",
    "prediction = clf.predict(input_data_with_additional_features)\n",
    "print(prediction)\n",
    "\n",
    "if prediction[0] == 0:\n",
    "    print('The person does not have heart disease.')\n",
    "else:\n",
    "    print('The person has heart disease.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708de03-f8f1-49ec-a82b-a522d903f782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b49a2e-053d-457c-a4bf-a379135b3df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
